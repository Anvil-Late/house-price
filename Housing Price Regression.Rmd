---
title: "Housing Price Regression"
author: "Anvil"
date: "14/09/2020"
output: 
   html_document:
      code_folding: show
      keep_md : true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```

# Summary

# Loading packages

Throughout this project, we will use :

- ggplot2
- dplyr
- data.table
- corrplot
- caret
- randomForest

```{r}
library(ggplot2)
library(dplyr)
library(data.table)
library(corrplot)
library(caret)
library(randomForest)
library(gbm)

```

# Loading the data

As a personal habit, I automate the downloading and loading processes. The original data can be found on [this Kaggle page](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview)

```{r}

# This will create a "data" folder in the current directory and store the data in it

if (!file.exists("data")){
   dir.create("data")
}

trainurl <- "https://storage.googleapis.com/kagglesdsdata/competitions/5407/868283/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1600334118&Signature=m8A295cdrmCFr1Qo8tweV0krSrzo%2Flis%2B51piiEOmc%2BKUYKQzUshHC2uG00JWzt03KkMDFiz0FpHO95VLzEQFddzD%2B%2Byi43nEGe0XfEXYP7wAKUrEPGTDY0kRtf3Y7n50JDmhp0WGnxzVK47FH1xbuJFacvWhnpAwO78fhVQH6x0HiNsfz8U2rYtkHefSaBy08Dnztggx%2BWEd0Q9vEA4mtqRuT%2Btd4%2FNra2n0BDdZUZ4BDQGaxdXU6aSDoP9XYMv6vbB4%2FFH13YCxbnUr3JuS85g%2FTxM%2Ba5pkmGq1rnijPXHqwRA9WKK%2BFSVhuZ%2Fv3N65u9vUCsnY2kAox26vnd3HQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv"

trainfile <- "./data/train.csv"

testurl <- "https://storage.googleapis.com/kagglesdsdata/competitions/5407/868283/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1600334123&Signature=RgHIdDwVbnPVzd34JSDORiVnsqzsL%2B7OCr%2BQHKjNprCjj58ipSaQLwDKWo73vDLK9hEcRN6kqYMn3%2FVvnO9zX5HY5H%2FCXz6TUoq9iPkA8qLpwPqIv32O96aHb9of6%2BKX%2FLbw1r%2FQKiZOc%2FmIVe13zB7qGcjZaREDJH9v2dBbAIh4SBrc09vgMEzvJS5XqBcw3HuQHmPDfCsboYMFLTH%2F7uV5PPuVvB%2Fr%2BvsDZsR46OOz1gdTKdS1qYcjfa2w%2FJNYpKJ2uAeSAjpulyAKSSyf3FxJQS0EF%2BqqWRrtWE8X%2FIEAZlRKosWHIdLy%2FENyjX0d3Ltpylkd9neTPebQXjj6Yw%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.csv"

testfile <- "./data/test.csv"

if (!file.exists(trainfile)){
   download.file(trainurl, trainfile, method = "curl")
}

if (!file.exists(testfile)){
   download.file(testurl, testfile, method = "curl")
}

test <- read.csv(testfile)
train <- read.csv(trainfile)
```

# Exploratory data analysis

It's now time to take a look at our data. The first thing we'll do is to convert both train and test sets to data tables to make future modifications easier. 

```{r}
train <- data.table(train)
test <- data.table(test)
```

## Data Partition



We'll split our training set into a sub-train and sub-test set with a 70-30 partition :

```{r}
set.seed(1234)
splitter <- createDataPartition(y=train$SalePrice, p=0.7, list = F)
subtest <- train[-splitter, ]
train <- train[splitter, ]
```

## Variables' class

Let's have a look at our training set, and especially the class of its variables :
```{r}
train[, lapply(.SD, class), .SDcols = names(train[,1:14])]
```
We have a lot of character variables; the [data description file provided by kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) indicates that these are classification variables with only a few possible values. They should therefore be converted to factors.

```{r}
to_factor <- names(which(sapply(train, class) == "character"))
```

Similarly, while some of the integer or numeric vectors indicate a truly numeric value, such as *LotArea* which indicates the lot size in square feet, others are - again - classification variables, such as *MSSubClass*, which identifies the type of dwelling involved in the sale, with, for instance, 20 signifying "1-STORY 1946 & NEWER ALL STYLES" (see data description file). 
We have 3 such variables : *MSSubClass*, *OverallQual*, and *OverallCond*.

These will also have to be converted to factor.


```{r}
to_factor <- c(to_factor,"MSSubClass", "OverallQual", "OverallCond")

```



## Dates

We have 4 variables that contain date information :

- YearBuilt: Original construction date
- YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)
- GarageYrBlt: Year garage was built
- YrSold: Year Sold

Intuitively, it can be said that these variables, especially the construction date, can have an impact on the final price, which seems to be confirmed in this plot :

```{r}
qplot(train$YearBuilt, train$SalePrice) + labs(x = "Construction Date",
                                               y = "House Sale Price") +
   ggtitle("House sale price by year of construction")

```

Looking at the range of dates and their linear relationship with the sale price, we'll keep the dates variables as integer.

However, the *GarageYrBlt* variable is problematic since it is set to NA when there is no garage, and can cause trouble when we preprocess missing values (we'll get to NAs in general in a minute). 

Therefore, we'll either remove this variable if it contributes little to the data set or convert it to factor with a "none" level if it does.

We'll check if this variable is highly correlated to others. Let's see the correlation percentage between *YearBuilt* and *GarageYrBlt* :

```{r}
cor(train$YearBuilt, train$GarageYrBlt, use = "complete")
```
Therefore, we can say that this variable contributes little to the dataset, and we can safely remove it.

## Missing values (NAs) 

Before we convert these variables to factor and go forward into the analysis, we need to first have a look at the proportion of NAs in the dataset.

Let's first see which columns have NAs :

```{r}
temp_na <- as.numeric(train[, lapply(.SD, function(y){sum(is.na(y))})])
names(temp_na) <- names(train)
temp_na <- temp_na[temp_na > 0]
print(temp_na)
```

We have about 4900 NAs, which is around 6% of our data. However, the description file indicates that for some variables, NA doesn't mean a missing value but an absence of feature. For instance, for the *Alley* column, NA signifiest that there is no alley access.

Therefore, in some cases, NAs contain valuable information, and since we might do some pre-processing to convert missing values later on and we don't want to change this type of NA, we'll change them to a "None" level for factor variables.

The factor variables concerned by this are *Alley*, *BsmtQual*, *BsmtCond*, *BsmtExposure*, *BsmtFinType1*, *BsmtFinType2*, *FireplaceQu*, *GarageType*, *GarageFinish*, *GarageQual*, *GarageCond*, *PoolQC*, *Fence*, and *MiscFeature*. As seen previously, we ignore *GarageYrBlt* since we will remove this variable


```{r}
temp_na2 <- temp_na[temp_na> 10][-c(1,10)]

print(temp_na2)
```

## Data cleaning

We will now take all that have been said so far to clean the data. We will also remove the first column since it is the ID variable for the various houses in our dataset.

```{r}
# Step 1 : convert NAs 
for (j in names(temp_na2)){
   set(train,which(is.na(train[[j]])),j,"None")
}

# Step 2 :  convert to factor

train[, (to_factor) := lapply(.SD, as.factor), .SDcols = to_factor]

# step 3 : Delete ID and GarageYrBuilt variables
train <- train[, -c(1,60)]
```

## Correlation

Since there are 81 total variables, of which 33 are numeric, it might be useful to look for redundancies between variables.

In other words, we would like to se a correlation plot of numeric variables and remove those that are heavily correlated to others :

```{r, echo=F}
# This is a modified version of corrplot that prevents labels to go out of frame
corrplot2 <- 
   function (corr, method = c("circle", "square", "ellipse", "number", 
                              "shade", "color", "pie"), type = c("full", "lower", "upper"), 
             add = FALSE, col = NULL, bg = "white", title = "", is.corr = TRUE, 
             diag = TRUE, outline = FALSE, mar = c(0, 0, 0, 0), addgrid.col = NULL, 
             addCoef.col = NULL, addCoefasPercent = FALSE, order = c("original", 
                                                                     "AOE", "FPC", "hclust", "alphabet"), hclust.method = c("complete", 
                                                                                                                            "ward", "ward.D", "ward.D2", "single", "average", "mcquitty", 
                                                                                                                            "median", "centroid"), addrect = NULL, rect.col = "black", 
             rect.lwd = 2, tl.pos = NULL, tl.cex = 1, tl.col = "red", 
             tl.offset = 0.4, tl.srt = 90, cl.pos = NULL, cl.lim = NULL, 
             cl.length = NULL, cl.cex = 0.8, cl.ratio = 0.15, cl.align.text = "c", 
             cl.offset = 0.5, number.cex = 1, number.font = 2, number.digits = NULL, 
             addshade = c("negative", "positive", "all"), shade.lwd = 1, 
             shade.col = "white", p.mat = NULL, sig.level = 0.05, insig = c("pch", 
                                                                            "p-value", "blank", "n"), pch = 4, pch.col = "black", 
             pch.cex = 3, plotCI = c("n", "square", "circle", "rect"), 
             lowCI.mat = NULL, uppCI.mat = NULL, na.label = "?", na.label.col = "black",
             h.ratio = FALSE,
             ...){
      method <- match.arg(method)
      type <- match.arg(type)
      order <- match.arg(order)
      hclust.method <- match.arg(hclust.method)
      plotCI <- match.arg(plotCI)
      insig <- match.arg(insig)
      if (!is.matrix(corr) && !is.data.frame(corr)) {
         stop("Need a matrix or data frame!")
      }
      if (is.null(addgrid.col)) {
         addgrid.col <- switch(method, color = NA, shade = NA, 
                               "grey")
      }
      if (any(corr < cl.lim[1]) || any(corr > cl.lim[2])) {
         stop("color limits should cover matrix")
      }
      if (is.null(cl.lim)) {
         if (is.corr) {
            cl.lim <- c(-1, 1)
         }
         else {
            cl.lim <- c(min(corr), max(corr))
         }
      }
      intercept <- 0
      zoom <- 1
      if (!is.corr) {
         if (max(corr) * min(corr) < 0) {
            intercept <- 0
            zoom <- 1/max(abs(cl.lim))
         }
         if (min(corr) >= 0) {
            intercept <- -cl.lim[1]
            zoom <- 1/(diff(cl.lim))
         }
         if (max(corr) <= 0) {
            intercept <- -cl.lim[2]
            zoom <- 1/(diff(cl.lim))
         }
         corr <- (intercept + corr) * zoom
      }
      cl.lim2 <- (intercept + cl.lim) * zoom
      int <- intercept * zoom
      if (min(corr, na.rm = TRUE) < -1 - .Machine$double.eps^0.75 || 
          max(corr, na.rm = TRUE) > 1 + .Machine$double.eps^0.75) {
         stop("The matrix is not in [-1, 1]!")
      }
      if (is.null(col)) {
         col <- colorRampPalette(c("#67001F", "#B2182B", "#D6604D", 
                                   "#F4A582", "#FDDBC7", "#FFFFFF", "#D1E5F0", "#92C5DE", 
                                   "#4393C3", "#2166AC", "#053061"))(200)
      }
      n <- nrow(corr)
      m <- ncol(corr)
      min.nm <- min(n, m)
      ord <- seq_len(min.nm)
      if (order != "original") {
         ord <- corrMatOrder(corr, order = order, hclust.method = hclust.method)
         corr <- corr[ord, ord]
      }
      if (is.null(rownames(corr))) {
         rownames(corr) <- seq_len(n)
      }
      if (is.null(colnames(corr))) {
         colnames(corr) <- seq_len(m)
      }
      apply_mat_filter <- function(mat) {
         x <- matrix(1:n * m, n, m)
         switch(type, upper = mat[row(x) > col(x)] <- Inf, lower = mat[row(x) < 
                                                                          col(x)] <- Inf)
         if (!diag) {
            diag(mat) <- Inf
         }
         return(mat)
      }
      getPos.Dat <- function(mat) {
         tmp <- apply_mat_filter(mat)
         Dat <- tmp[is.finite(tmp)]
         ind <- which(is.finite(tmp), arr.ind = TRUE)
         Pos <- ind
         Pos[, 1] <- ind[, 2]
         Pos[, 2] <- -ind[, 1] + 1 + n
         return(list(Pos, Dat))
      }
      getPos.NAs <- function(mat) {
         tmp <- apply_mat_filter(mat)
         ind <- which(is.na(tmp), arr.ind = TRUE)
         Pos <- ind
         Pos[, 1] <- ind[, 2]
         Pos[, 2] <- -ind[, 1] + 1 + n
         return(Pos)
      }
      Pos <- getPos.Dat(corr)[[1]]
      n2 <- max(Pos[, 2])
      n1 <- min(Pos[, 2])
      nn <- n2 - n1
      newrownames <- as.character(rownames(corr)[(n + 1 - n2):(n + 
                                                                  1 - n1)])
      m2 <- max(Pos[, 1])
      m1 <- min(Pos[, 1])
      mm <- max(1, m2 - m1)
      newcolnames <- as.character(colnames(corr)[m1:m2])
      DAT <- getPos.Dat(corr)[[2]]
      len.DAT <- length(DAT)
      assign.color <- function(dat = DAT, color = col) {
         newcorr <- (dat + 1)/2
         newcorr[newcorr <= 0] <- 0
         newcorr[newcorr >= 1] <- 1 - 1e-16
         color[floor(newcorr * length(color)) + 1]
      }
      col.fill <- assign.color()
      isFALSE <- function(x) identical(x, FALSE)
      isTRUE <- function(x) identical(x, TRUE)
      if (isFALSE(tl.pos)) {
         tl.pos <- "n"
      }
      if (is.null(tl.pos) || isTRUE(tl.pos)) {
         tl.pos <- switch(type, full = "lt", lower = "ld", upper = "td")
      }
      if (isFALSE(cl.pos)) {
         cl.pos <- "n"
      }
      if (is.null(cl.pos) || isTRUE(cl.pos)) {
         cl.pos <- switch(type, full = "r", lower = "b", upper = "r")
      }
      if (isFALSE(outline)) {
         col.border <- col.fill
      }
      if (isTRUE(outline)) {
         col.border <- "black"
      }
      if (is.character(outline)) {
         col.border <- outline
      }
      oldpar <- par(mar = mar, bg = "white")
      on.exit(par(oldpar), add = TRUE)
      if (!add) {
         plot.new()
         xlabwidth <- max(strwidth(newrownames, cex = tl.cex))
         ylabwidth <- max(strwidth(newcolnames, cex = tl.cex))
         laboffset <- strwidth("W", cex = tl.cex) * tl.offset 
         
         for (i in 1:50) { # 200
            
            xlim <- c(
               m1 - 0.5 - xlabwidth * (grepl("l", tl.pos) | grepl("d", tl.pos)) - laboffset
               , 
               m2 + 0.5 + mm * cl.ratio * (cl.pos == "r") +
                  xlabwidth * abs(cos(tl.srt * pi/180)) * grepl("d", tl.pos) 
            ) + c(-0.35, 0.15)
            + c(-1,0) * grepl("l", tl.pos) # margin between text and grid
            
            ylim <- c(
               n1 - 0.5 - nn * cl.ratio * (cl.pos == "b")
               , 
               # n2 + 0.5 + ylabwidth + laboffset +
               n2 + 0.5 + laboffset + 
                  ylabwidth * abs(sin(tl.srt * pi/180)) * (grepl("d", tl.pos) | grepl("t", tl.pos)) 
            ) + c(-0.15, 0.2)
            + c(0,1) * grepl("d", tl.pos) # margin between text and grid
            
            plot.window(xlim, ylim,     
                        # plot.window(xlim + c(-0.35, 0.15), ylim + c(-0.15, 0.35), 
                        asp = 1, xaxs = "i", yaxs = "i")
            x.tmp <- max(strwidth(newrownames, cex = tl.cex))
            y.tmp <- max(strwidth(newcolnames, cex = tl.cex))
            laboffset.tmp <- strwidth("W", cex = tl.cex) * tl.offset            
            # if (min(x.tmp - xlabwidth, y.tmp - ylabwidth) < 1e-03) {
            if (max(x.tmp - xlabwidth, y.tmp - ylabwidth, laboffset.tmp - laboffset) < 1e-03) {
               break
            }
            xlabwidth <- x.tmp
            ylabwidth <- y.tmp
            laboffset <- laboffset.tmp
            
            if (i == 50) {
               warning(c("Not been able to calculate text margin, ",
                         "please try again with a clean new empty window using {plot.new(); dev.off()} ",
                         "or reduce tl.cex"))
            }
         }
         
         #         if (tl.pos == "n" || tl.pos == "d") {
         #             xlabwidth <- ylabwidth <- 0
         #         }
         #         if (tl.pos == "td") {
         #             ylabwidth <- 0
         #         }
         #         if (tl.pos == "ld") 
         # xlabwidth <- 0 # Modified by Seb
         #         laboffset <- strwidth("W", cex = tl.cex) * tl.offset
         #         xlim <- c(m1 - 0.5 - xlabwidth - laboffset, m2 + 0.5 + 
         #             mm * cl.ratio * (cl.pos == "r") + xlabwidth * cos(tl.srt * pi/180)) + c(-0.35, 0.15)
         #             # mm * cl.ratio * (cl.pos == "r")) + c(-0.35, 0.15))
         #         ylim <- c(n1 - 0.5 - nn * cl.ratio * (cl.pos == "b"), 
         #             n2 + 0.5 + ylabwidth * abs(sin(tl.srt * pi/180)) + 
         #                 laboffset) + c(-0.15, 0.35)
         
         
         if (.Platform$OS.type == "windows") {
            grDevices::windows.options(width = 7, height = 7 * 
                                          diff(ylim)/diff(xlim))
         } else {
            if (round(diff(ylim)/diff(xlim), digits = 1) != 1.0) {
               message(paste0("Suggested windows size: height = width * ", round(diff(ylim)/diff(xlim), digits = 2)))
            }
         }
         if (h.ratio) {
            h.ratio.val <- diff(ylim)/diff(xlim)
         }
         
         plot.window(xlim = xlim, ylim = ylim, asp = 1, xlab = "", 
                     ylab = "", xaxs = "i", yaxs = "i")
      }
      laboffset <- strwidth("W", cex = tl.cex) * tl.offset
      symbols(Pos, add = TRUE, inches = FALSE, squares = rep(1, 
                                                             len.DAT), bg = bg, fg = bg)
      if (method == "circle" && plotCI == "n") {
         symbols(Pos, add = TRUE, inches = FALSE, circles = 0.9 * 
                    abs(DAT)^0.5/2, fg = col.border, bg = col.fill)
      }
      if (method == "ellipse" && plotCI == "n") {
         ell.dat <- function(rho, length = 99) {
            k <- seq(0, 2 * pi, length = length)
            x <- cos(k + acos(rho)/2)/2
            y <- cos(k - acos(rho)/2)/2
            return(cbind(rbind(x, y), c(NA, NA)))
         }
         ELL.dat <- lapply(DAT, ell.dat)
         ELL.dat2 <- 0.85 * matrix(unlist(ELL.dat), ncol = 2, 
                                   byrow = TRUE)
         ELL.dat2 <- ELL.dat2 + Pos[rep(1:length(DAT), each = 100), 
         ]
         polygon(ELL.dat2, border = col.border, col = col.fill)
      }
      if (is.null(number.digits)) {
         number.digits <- switch(addCoefasPercent + 1, 2, 0)
      }
      stopifnot(number.digits%%1 == 0)
      stopifnot(number.digits >= 0)
      if (method == "number" && plotCI == "n") {
         text(Pos[, 1], Pos[, 2], font = number.font, col = col.fill, 
              labels = round((DAT - int) * ifelse(addCoefasPercent, 
                                                  100, 1)/zoom, number.digits), cex = number.cex)
      }
      NA_LABEL_MAX_CHARS <- 2
      if (any(is.na(corr)) && is.character(na.label)) {
         PosNA <- getPos.NAs(corr)
         if (na.label == "square") {
            symbols(PosNA, add = TRUE, inches = FALSE, squares = rep(1, 
                                                                     nrow(PosNA)), bg = na.label.col, fg = na.label.col)
         }
         else if (nchar(na.label) %in% 1:NA_LABEL_MAX_CHARS) {
            symbols(PosNA, add = TRUE, inches = FALSE, squares = rep(1, 
                                                                     nrow(PosNA)), fg = bg, bg = bg)
            text(PosNA[, 1], PosNA[, 2], font = number.font, 
                 col = na.label.col, labels = na.label, cex = number.cex, 
                 ...)
         }
         else {
            stop(paste("Maximum number of characters for NA label is:", 
                       NA_LABEL_MAX_CHARS))
         }
      }
      if (method == "pie" && plotCI == "n") {
         symbols(Pos, add = TRUE, inches = FALSE, circles = rep(0.5, 
                                                                len.DAT) * 0.85)
         pie.dat <- function(theta, length = 100) {
            k <- seq(pi/2, pi/2 - theta, length = 0.5 * length * 
                        abs(theta)/pi)
            x <- c(0, cos(k)/2, 0)
            y <- c(0, sin(k)/2, 0)
            cbind(rbind(x, y), c(NA, NA))
         }
         PIE.dat <- lapply(DAT * 2 * pi, pie.dat)
         len.pie <- unlist(lapply(PIE.dat, length))/2
         PIE.dat2 <- 0.85 * matrix(unlist(PIE.dat), ncol = 2, 
                                   byrow = TRUE)
         PIE.dat2 <- PIE.dat2 + Pos[rep(1:length(DAT), len.pie), 
         ]
         polygon(PIE.dat2, border = "black", col = col.fill)
      }
      if (method == "shade" && plotCI == "n") {
         addshade <- match.arg(addshade)
         symbols(Pos, add = TRUE, inches = FALSE, squares = rep(1, 
                                                                len.DAT), bg = col.fill, fg = addgrid.col)
         shade.dat <- function(w) {
            x <- w[1]
            y <- w[2]
            rho <- w[3]
            x1 <- x - 0.5
            x2 <- x + 0.5
            y1 <- y - 0.5
            y2 <- y + 0.5
            dat <- NA
            if ((addshade == "positive" || addshade == "all") && 
                rho > 0) {
               dat <- cbind(c(x1, x1, x), c(y, y1, y1), c(x, 
                                                          x2, x2), c(y2, y2, y))
            }
            if ((addshade == "negative" || addshade == "all") && 
                rho < 0) {
               dat <- cbind(c(x1, x1, x), c(y, y2, y2), c(x, 
                                                          x2, x2), c(y1, y1, y))
            }
            return(t(dat))
         }
         pos_corr <- rbind(cbind(Pos, DAT))
         pos_corr2 <- split(pos_corr, 1:nrow(pos_corr))
         SHADE.dat <- matrix(na.omit(unlist(lapply(pos_corr2, 
                                                   shade.dat))), byrow = TRUE, ncol = 4)
         segments(SHADE.dat[, 1], SHADE.dat[, 2], SHADE.dat[, 
                                                            3], SHADE.dat[, 4], col = shade.col, lwd = shade.lwd)
      }
      if (method == "square" && plotCI == "n") {
         symbols(Pos, add = TRUE, inches = FALSE, squares = abs(DAT)^0.5, 
                 bg = col.fill, fg = col.border)
      }
      if (method == "color" && plotCI == "n") {
         symbols(Pos, add = TRUE, inches = FALSE, squares = rep(1, 
                                                                len.DAT), bg = col.fill, fg = col.border)
      }
      symbols(Pos, add = TRUE, inches = FALSE, bg = NA, squares = rep(1, 
                                                                      len.DAT), fg = addgrid.col)
      if (plotCI != "n") {
         if (is.null(lowCI.mat) || is.null(uppCI.mat)) {
            stop("Need lowCI.mat and uppCI.mat!")
         }
         if (order != "original") {
            lowCI.mat <- lowCI.mat[ord, ord]
            uppCI.mat <- uppCI.mat[ord, ord]
         }
         pos.lowNew <- getPos.Dat(lowCI.mat)[[1]]
         lowNew <- getPos.Dat(lowCI.mat)[[2]]
         pos.uppNew <- getPos.Dat(uppCI.mat)[[1]]
         uppNew <- getPos.Dat(uppCI.mat)[[2]]
         if (!method %in% c("circle", "square")) {
            stop("method shoud be circle or square if draw confidence interval!")
         }
         k1 <- (abs(uppNew) > abs(lowNew))
         bigabs <- uppNew
         bigabs[which(!k1)] <- lowNew[!k1]
         smallabs <- lowNew
         smallabs[which(!k1)] <- uppNew[!k1]
         sig <- sign(uppNew * lowNew)
         color_bigabs <- col[ceiling((bigabs + 1) * length(col)/2)]
         color_smallabs <- col[ceiling((smallabs + 1) * length(col)/2)]
         if (plotCI == "circle") {
            symbols(pos.uppNew[, 1], pos.uppNew[, 2], add = TRUE, 
                    inches = FALSE, circles = 0.95 * abs(bigabs)^0.5/2, 
                    bg = ifelse(sig > 0, col.fill, color_bigabs), 
                    fg = ifelse(sig > 0, col.fill, color_bigabs))
            symbols(pos.lowNew[, 1], pos.lowNew[, 2], add = TRUE, 
                    inches = FALSE, circles = 0.95 * abs(smallabs)^0.5/2, 
                    bg = ifelse(sig > 0, bg, color_smallabs), fg = ifelse(sig > 
                                                                             0, col.fill, color_smallabs))
         }
         if (plotCI == "square") {
            symbols(pos.uppNew[, 1], pos.uppNew[, 2], add = TRUE, 
                    inches = FALSE, squares = abs(bigabs)^0.5, bg = ifelse(sig > 
                                                                              0, col.fill, color_bigabs), fg = ifelse(sig > 
                                                                                                                         0, col.fill, color_bigabs))
            symbols(pos.lowNew[, 1], pos.lowNew[, 2], add = TRUE, 
                    inches = FALSE, squares = abs(smallabs)^0.5, 
                    bg = ifelse(sig > 0, bg, color_smallabs), fg = ifelse(sig > 
                                                                             0, col.fill, color_smallabs))
         }
         if (plotCI == "rect") {
            rect.width <- 0.25
            rect(pos.uppNew[, 1] - rect.width, pos.uppNew[, 2] + 
                    smallabs/2, pos.uppNew[, 1] + rect.width, pos.uppNew[, 
                                                                         2] + bigabs/2, col = col.fill, border = col.fill)
            segments(pos.lowNew[, 1] - rect.width, pos.lowNew[, 
                                                              2] + DAT/2, pos.lowNew[, 1] + rect.width, pos.lowNew[, 
                                                                                                                   2] + DAT/2, col = "black", lwd = 1)
            segments(pos.uppNew[, 1] - rect.width, pos.uppNew[, 
                                                              2] + uppNew/2, pos.uppNew[, 1] + rect.width, 
                     pos.uppNew[, 2] + uppNew/2, col = "black", lwd = 1)
            segments(pos.lowNew[, 1] - rect.width, pos.lowNew[, 
                                                              2] + lowNew/2, pos.lowNew[, 1] + rect.width, 
                     pos.lowNew[, 2] + lowNew/2, col = "black", lwd = 1)
            segments(pos.lowNew[, 1] - 0.5, pos.lowNew[, 2], 
                     pos.lowNew[, 1] + 0.5, pos.lowNew[, 2], col = "grey70", 
                     lty = 3)
         }
      }
      if (!is.null(p.mat) && insig != "n") {
         if (order != "original") {
            p.mat <- p.mat[ord, ord]
         }
         pos.pNew <- getPos.Dat(p.mat)[[1]]
         pNew <- getPos.Dat(p.mat)[[2]]
         ind.p <- which(pNew > sig.level)
         p_inSig <- length(ind.p) > 0
         if (insig == "pch" && p_inSig) {
            points(pos.pNew[, 1][ind.p], pos.pNew[, 2][ind.p], 
                   pch = pch, col = pch.col, cex = pch.cex, lwd = 2)
         }
         if (insig == "p-value" && p_inSig) {
            text(pos.pNew[, 1][ind.p], pos.pNew[, 2][ind.p], 
                 round(pNew[ind.p], 2), col = pch.col)
         }
         if (insig == "blank" && p_inSig) {
            symbols(pos.pNew[, 1][ind.p], pos.pNew[, 2][ind.p], 
                    inches = FALSE, squares = rep(1, length(pos.pNew[, 
                                                                     1][ind.p])), fg = addgrid.col, bg = bg, add = TRUE)
         }
      }
      if (cl.pos != "n") {
         colRange <- assign.color(dat = cl.lim2)
         ind1 <- which(col == colRange[1])
         ind2 <- which(col == colRange[2])
         colbar <- col[ind1:ind2]
         if (is.null(cl.length)) {
            cl.length <- ifelse(length(colbar) > 20, 11, length(colbar) + 
                                   1)
         }
         labels <- seq(cl.lim[1], cl.lim[2], length = cl.length)
         if (cl.pos == "r") {
            vertical <- TRUE
            xlim <- c(m2 + 0.5 + mm * 0.02, m2 + 0.5 + mm * cl.ratio)
            ylim <- c(n1 - 0.5, n2 + 0.5)
         }
         if (cl.pos == "b") {
            vertical <- FALSE
            xlim <- c(m1 - 0.5, m2 + 0.5)
            ylim <- c(n1 - 0.5 - nn * cl.ratio, n1 - 0.5 - nn * 
                         0.02)
         }
         colorlegend(colbar = colbar, labels = round(labels, 2), 
                     offset = cl.offset, ratio.colbar = 0.3, cex = cl.cex, 
                     xlim = xlim, ylim = ylim, vertical = vertical, align = cl.align.text)
      }
      if (tl.pos != "n") {
         pos.xlabel <- cbind(m1:m2, n2 + 0.5 + laboffset)
         pos.ylabel <- cbind(m1 - 0.5, n2:n1)
         if (tl.pos == "td") {
            if (type != "upper") {
               stop("type should be \"upper\" if tl.pos is \"dt\".")
            }
            pos.ylabel <- cbind(m1:(m1 + nn) - 0.5, n2:n1)
         }
         if (tl.pos == "ld") {
            if (type != "lower") {
               stop("type should be \"lower\" if tl.pos is \"ld\".")
            }
            pos.xlabel <- cbind(m1:m2, n2:(n2 - mm) + 0.5 + laboffset)
         }
         if (tl.pos == "d") {
            pos.ylabel <- cbind(m1:(m1 + nn) - 0.5, n2:n1)
            pos.ylabel <- pos.ylabel[1:min(n, m), ]
            symbols(pos.ylabel[, 1] + 0.5, pos.ylabel[, 2], add = TRUE, 
                    bg = bg, fg = addgrid.col, inches = FALSE, squares = rep(1, 
                                                                             length(pos.ylabel[, 1])))
            text(pos.ylabel[, 1] + 0.5, pos.ylabel[, 2], newcolnames[1:min(n, 
                                                                           m)], col = tl.col, cex = tl.cex, ...)
         }
         else {
            text(pos.xlabel[, 1], pos.xlabel[, 2], newcolnames, 
                 srt = tl.srt, adj = ifelse(tl.srt == 0, c(0.5, 
                                                           0), c(0, 0)), col = tl.col, cex = tl.cex, offset = tl.offset, 
                 ...)
            text(pos.ylabel[, 1], pos.ylabel[, 2], newrownames, 
                 col = tl.col, cex = tl.cex, pos = 2, offset = tl.offset, 
                 ...)
         }
      }
      title(title, ...)
      if (!is.null(addCoef.col) && method != "number") {
         text(Pos[, 1], Pos[, 2], col = addCoef.col, labels = round((DAT - 
                                                                        int) * ifelse(addCoefasPercent, 100, 1)/zoom, number.digits), 
              cex = number.cex, font = number.font)
      }
      if (type == "full" && plotCI == "n" && !is.null(addgrid.col)) {
         rect(m1 - 0.5, n1 - 0.5, m2 + 0.5, n2 + 0.5, border = addgrid.col)
      }
      if (!is.null(addrect) && order == "hclust" && type == "full") {
         corrRect.hclust(corr, k = addrect, method = hclust.method, 
                         col = rect.col, lwd = rect.lwd)
      }
      invisible(corr)
      if (h.ratio) {
         return(h.ratio = h.ratio.val)
      }
   }
```

```{r}
integer_cols <- sapply(train, function(y){class(y) == "integer"})
integer_train <- train[, .SD, .SDcols = integer_cols]
integer_train <- integer_train[, 1:32] # remove "SalePrice column

train_cor <- cor(integer_train, use = "complete")

# Corrplot2 is a modified version of corrplot that prevents labels to go out of
# the image's frame. If you're interested, it will be on my .Rmd file
corrplot2(train_cor, method = "square", type = "lower", 
         title = "Correlation plot between numeric variables",
         tl.col = "black", tl.cex = 0.6, order = "hclust",
         mar = c(0,0,2,0))
```
We find that there are some variables that have strong correlations with each other :

- GarageCars and GarageArea
- 1stFlrSF (First Floor square feet) and TotalBsmtSF (Total square feet of basement area)
- TotRmsAbvGrd (Total rooms above grade) and GrLivArea (Above grade living area square feet)

Below are their correlation coefficients :

```{r}
cor(train$GarageCars, train$GarageArea)
cor(train$X1stFlrSF, train$TotalBsmtSF)
cor(train$TotRmsAbvGrd, train$GrLivArea)
```

Moreover, GarageCars, GrLivArea and TotalBsmtSF are heavily correlated to other variables. We will therefore remove them from the dataset.

```{r}
train <- train[, -c(38, 46, 60)]
```

# Preprocessing

Now that we looked at our data, cleaned it and selected the variables that we will use, it is time to do some pre-processing. Here, we will fill in the NAs. Given the low proportion of NAs, the dataset's size and the general similarities between rows and variables, we will use the KNN-Impute algorithm.

```{r}
preObj <- preProcess(train[, -76], method = "knnImpute")
proc_train <- data.table(cbind(predict(preObj, train[, -76]), train[, 76]))
```

KNN-Imputing removed the majority of our NAs, but there might be some that remain in our factor variables, for which our algorithm could do nothing for. Let's see if there are some that remain :

```{r}
which(is.na(proc_train), arr.ind = T)
```

we have 5 rows that contain NAs. We will remove them from the set

```{r}
proc_train <- proc_train[-c(376, 463, 690, 692, 970), ]
```

## Levels



```{r}
train_original <- read.csv(trainfile)
train_original <- data.table(train_original)
for (j in names(temp_na2)){
   set(train_original,which(is.na(train_original[[j]])),j,"None")
}
train_original[, (to_factor) := lapply(.SD, as.factor), .SDcols = to_factor]
train_original <- train_original[, -c(1,60)]
train_original <- train_original[, -c(38, 46, 60)]
level_list <- list()
for (j in names(train_original)){
   if (class(train_original[[j]]) == "factor"){
      level_list <- c(level_list, list(levels(train_original[[j]])))
   }else{
      level_list <- c(level_list, list(NULL))
   }
}
```

```{r}
for (j in 1:dim(train)[2]){
   if (class(train[[names(train)[j]]]) == "factor"){
      levels(train[[names(train)[j]]]) <- level_list[[j]]
   }
}

for (j in 1:dim(proc_train)[2]){
   if (class(proc_train[[names(proc_train)[j]]]) == "factor"){
      levels(proc_train[[names(proc_train)[j]]]) <- level_list[[j]]
   }
}


```

# Model Building

For now, we will build a model using the random forest algorithm, and see how well it performs.
If it's lacking, we'll try using a combination of models.

```{r, eval=F}
modfit_rf <- randomForest(SalePrice ~ ., data = proc_train)
modfit_boost <- gbm(SalePrice ~ ., data = proc_train)

```

```{r, echo=F}
load("./data/modfit_rf.RData")
load("./data/modfit_boost.RData")
```

We'll preprocess the sub-test set in the same way we did the train set :


```{r}
for (j in names(temp_na2)){
   set(subtest,which(is.na(subtest[[j]])),j,"None")
}

subtest[, (to_factor) := lapply(.SD, as.factor), .SDcols = to_factor]

subtest <- subtest[, -c(1,60)]
subtest <- subtest[, -c(38, 46, 60)]

proc_subtest <- data.table(predict(preObj, subtest[, -76]))

for (j in 1:dim(proc_subtest)[2]){
   if (class(proc_subtest[[names(proc_subtest)[j]]]) == "factor"){
      levels(proc_subtest[[names(proc_subtest)[j]]]) <- level_list[[j]]
   }
}

```

And now we predict :

```{r}
rf_predict <- predict(modfit_rf, proc_subtest)
boost_predict <- predict(modfit_boost, proc_subtest)
```

```{r}
comparison <- data.table(results = subtest$SalePrice, predicted_rf = rf_predict,
                         predicted_boost = boost_predict)
RMSE(comparison$results, comparison$predicted_rf, na.rm = T)
RMSE(comparison$results, comparison$predicted_boost, na.rm = T)
mean(comparison$results)
qplot(results, predicted_rf, data = comparison) + geom_abline(slope = 1, intercept = 0, colour = "red")
qplot(results, predicted_boost, data = comparison) + geom_abline(slope = 1, intercept = 0, colour = "red")

```

```{r}
numer_train <- proc_train %>% select(which(sapply(.,is.numeric)))

numer_train <- select(numer_train, -SalePrice)
svd1 <- svd(scale(numer_train))
qplot(1:dim(numer_train)[2], svd1$d^2 / sum(svd1$d^2)) + 
   labs(x = "columns", y = "Proportion of variance explained") +
   ggtitle("Proportion of variance explained per variable")
```

```{r}
preproc <- preProcess(numer_train, method = "pca", pcaComp = 20) 

numer_train <- data.table(predict(preproc, numer_train))
numer_train[ , Neighborhood := proc_train$Neighborhood] 
numer_train[ , SalePrice := proc_train$SalePrice]
```

```{r, eval=F}
modfit_glm <- train(SalePrice ~ ., method = "glm", data = numer_train)
```

```{r, echo=F}
load(file = "./data/modfit_glm.RData")
```

Preprocessing the subtest set :

```{r}
numer_subtest <- proc_subtest %>% select(which(sapply(.,is.numeric)))
numer_subtest <- data.table(predict(preproc, numer_subtest))
numer_subtest[ , Neighborhood := proc_subtest$Neighborhood] 
```

Prediction :

```{r}
predicted_glm <- predict(modfit_glm, numer_subtest)
```

```{r}
comparison[, predicted_glm := predicted_glm]
RMSE(comparison$results, comparison$predicted_glm, na.rm = T)
qplot(results, predicted_glm, data = comparison) + geom_abline(slope = 1, intercept = 0, colour = "red")
```

```{r}
exp_numtrain <- filter(numer_train, SalePrice > 300000)
```

```{r, eval=F}
modfit_expglm <- train(SalePrice ~ ., method = "glm", data = exp_numtrain)
```

```{r, echo=F}
load(file = "./data/modfit_expglm.RData")
```

Filter for proc_train saleprice > 300k

```{r}
exp_proctrain <- filter(proc_train, SalePrice > 300000)
```

New modfits for saleprice > 300k

```{r, eval=F}
modfit_exprf <- randomForest(SalePrice ~ ., data = exp_proctrain)
modfit_expboost <- gbm(SalePrice ~ ., data = exp_proctrain)
```
```{r,echo=F}
load(file = "./data/modfit_exprf.RData")
load(file = "./data/modfit_expboost.RData")
```

```{r}
predicted_exprf <- predict(modfit_exprf, proc_subtest)
predicted_expboost <- predict(modfit_expboost, proc_subtest)
predicted_expglm <- predict(modfit_expglm, numer_subtest)

comparison[, predicted_exprf := predicted_exprf]
comparison[, predicted_expboost := predicted_expboost]
comparison[, predicted_expglm := predicted_expglm]
RMSE(comparison$results, comparison$predicted_exprf, na.rm = T)
RMSE(comparison$results, comparison$predicted_expboost, na.rm = T)
RMSE(comparison$results, comparison$predicted_expglm, na.rm = T)
qplot(results, predicted_exprf, data = comparison) + geom_abline(slope = 1, intercept = 0, colour = "red")
qplot(results, predicted_expboost, data = comparison) + geom_abline(slope = 1, intercept = 0, colour = "red")
qplot(results, predicted_expglm, data = comparison) + geom_abline(slope = 1, intercept = 0, colour = "red")
```

combined :

```{r}

pred <- numeric()
for (i in 1:dim(comparison)[1]){
   if (comparison$results[i] <= 300000){
      pred <- c(pred, sum(comparison$predicted_rf[i], comparison$predicted_boost[i], 
                    comparison$predicted_glm[i], na.rm = T)/
                   sum(3-sum(is.na(c(comparison$predicted_rf[i], 
                                   comparison$predicted_boost[i], 
                                   comparison$predicted_glm[i])))))
                  # Kind of messy way to creat a mean, but mean() with an NA
                  # returns a NaN even with na.rm = T
   }else{
      pred <- c(pred, sum(comparison$predicted_exprf[i], comparison$predicted_expboost[i], 
                    comparison$predicted_expglm[i], na.rm = T)/
                   sum(3-sum(is.na(c(comparison$predicted_exprf[i], 
                                   comparison$predicted_expboost[i], 
                                   comparison$predicted_expglm[i])))))
   }
}

comparison[, prediction := pred]

RMSE(comparison$results, comparison$prediction, na.rm = T)
qplot(results, prediction, data = comparison) + geom_abline(slope = 1, intercept = 0, colour = "red")
```
Without outlier :

```{r}
temp <- copy(comparison)
temp[, delta := abs(results - prediction)]

rem_row <- which(temp$delta >= quantile(temp$delta)[5])
temp <- temp[-rem_row, ]
RMSE(temp$results, temp$prediction, na.rm = T)
qplot(results, prediction, data = temp) + geom_abline(slope = 1, intercept = 0, colour = "red")
```